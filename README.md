# BackPropagation-using-Computational-graph
Backpropagation and Gradient Checking is a classic Neural Network problem usedto solve the given computational graph. Given the computational graph first forwardpropagate and predict the class label. And finding the simple loss on actual and predictedvalues. Then computing the derivatives and updating the weights from end of thenetwork to staring of the network. And repeating the steps till convergence
